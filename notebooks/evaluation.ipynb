{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Honeypot LLM Evaluation Pipeline\n",
    "\n",
    " This notebook evaluates the performance of the Honeypot LLM by comparing its generated responses against reference outputs provided in `fewshots.json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "code_wrap": "ExecutionMagics",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "code_wrap": "ExecutionMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "mamba": "PackagingMagics",
        "matplotlib": "PylabMagics",
        "micromamba": "PackagingMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %code_wrap  %colors  %conda  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %mamba  %matplotlib  %micromamba  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%code_wrap  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%lsmagic  # Look for 'autoreload' in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking environment compatibility...\n",
      "Setup complete. If any packages were updated, please RESTART THE KERNEL now.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_packages():\n",
    "    print(\"Checking environment compatibility...\")\n",
    "    packages = [\n",
    "        \"numpy<2.0\", \"pandas\", \"matplotlib\", \"scipy\", \n",
    "        \"scikit-learn\", \"spacy\", \"jellyfish\", \"tqdm\", \"nltk\"\n",
    "    ]\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages)\n",
    "    \n",
    "    # Download spacy model if missing\n",
    "    try:\n",
    "        import spacy\n",
    "        if not spacy.util.is_package(\"en_core_web_sm\"):\n",
    "            print(\"Downloading spaCy model 'en_core_web_sm'...\")\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "    except ImportError:             \n",
    "        pass\n",
    "    \n",
    "    print(\"Setup complete. If any packages were updated, please RESTART THE KERNEL now.\")\n",
    "\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Setup] Server directory: c:\\Users\\shahd\\OneDrive\\Desktop\\v3.1 LLM-Honeypot-main\\v3.0 LLM-Honeypot-main\\honeypot-server\n",
      "[Setup] Data path: c:\\Users\\shahd\\OneDrive\\Desktop\\v3.1 LLM-Honeypot-main\\v3.0 LLM-Honeypot-main\\honeypot-server\\fewshots.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "import jellyfish\n",
    "from tqdm import tqdm\n",
    "from nltk.metrics.distance import edit_distance, jaro_winkler_similarity\n",
    "\n",
    "# Configuration\n",
    "current_dir = os.getcwd()\n",
    "SERVER_DIR = os.path.abspath(os.path.join(current_dir, \"..\", \"honeypot-server\"))\n",
    "DATA_PATH = os.path.join(SERVER_DIR, \"fewshots.json\")\n",
    "\n",
    "# Ensure server directory is in path\n",
    "if SERVER_DIR not in sys.path:\n",
    "    sys.path.append(SERVER_DIR)\n",
    "\n",
    "print(f\"[Setup] Server directory: {SERVER_DIR}\")\n",
    "print(f\"[Setup] Data path: {DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-2.8.1-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from openai) (1.8.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting jiter<1,>=0.10.0 (from openai)\n",
      "  Downloading jiter-0.12.0-cp311-cp311-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from openai) (2.12.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\shahd\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Using cached openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading jiter-0.12.0-cp311-cp311-win_amd64.whl (204 kB)\n",
      "   ---------------------------------------- 0.0/204.9 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/204.9 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 30.7/204.9 kB 262.6 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 41.0/204.9 kB 245.8 kB/s eta 0:00:01\n",
      "   ------- ------------------------------- 41.0/204.9 kB 245.8 kB/s eta 0:00:01\n",
      "   --------------- ----------------------- 81.9/204.9 kB 381.3 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 112.6/204.9 kB 437.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- 204.9/204.9 kB 593.5 kB/s eta 0:00:00\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: jiter, h11, httpcore, httpx, openai\n",
      "Successfully installed h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 jiter-0.12.0 openai-2.8.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Evaluation Data\n",
    "Loading reference commands and responses from `fewshots.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 1 â€” Install packages + Imports\n",
    "# ============================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from nltk.metrics.distance import edit_distance, jaro_winkler_similarity\n",
    "from llm import LLM\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load spaCy\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except:\n",
    "    nlp = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Models (Few-Shot vs Zero-Shot)\n",
    "We initialize two instances of the LLM:\n",
    "* **`few_shot_llm`**: Uses all available examples (`max_examples=None`).\n",
    "* **`base_llm`**: Uses zero examples (`max_examples=0`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shahd\\OneDrive\\Desktop\\v3.1 LLM-Honeypot-main\\v3.0 LLM-Honeypot-main\\notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully!\n",
      "Total samples: 1800\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>command</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grep root /etc/passwd /var/log/syslog</td>\n",
       "      <td>Unit sshd.service could not be found.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ip addr /tmp/file.txt</td>\n",
       "      <td>Output suppressed (no visible output)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>python3 script.py</td>\n",
       "      <td>(no output)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>umount /mnt</td>\n",
       "      <td>total 12\\ndrwxr-xr-x 2 root root 4096 Oct 20 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>whoami ./config.yaml</td>\n",
       "      <td>grep: /etc/passwd: Is a directory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 command  \\\n",
       "0  grep root /etc/passwd /var/log/syslog   \n",
       "1                  ip addr /tmp/file.txt   \n",
       "2                      python3 script.py   \n",
       "3                            umount /mnt   \n",
       "4                   whoami ./config.yaml   \n",
       "\n",
       "                                            response  \n",
       "0              Unit sshd.service could not be found.  \n",
       "1              Output suppressed (no visible output)  \n",
       "2                                        (no output)  \n",
       "3  total 12\\ndrwxr-xr-x 2 root root 4096 Oct 20 1...  \n",
       "4                  grep: /etc/passwd: Is a directory  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 2 â€” Load dataset\n",
    "# ============================\n",
    "\n",
    "DATA_PATH = \"fewshots.json\"\n",
    "\n",
    "with open(DATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.loads(f.read())\n",
    "\n",
    "df_all = pd.DataFrame(data)\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(\"Total samples:\", len(df_all))\n",
    "df_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Comparative Inference\n",
    "We will generate responses for the same commands using both models to compare directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 3 â€” Helper functions\n",
    "# ============================\n",
    "\n",
    "def random_sample(df_all):\n",
    "    \"\"\"Generate a random sample size each run.\"\"\"\n",
    "    sample_size = random.randint(30, 90)   # â† Ø§Ù†ØªÙŠ ØªÙ‚Ø¯Ø±ÙŠ ØªØºÙŠØ±ÙŠ Ø§Ù„Ø±ÙŠÙ†Ø¬\n",
    "    return df_all.sample(sample_size).reset_index(drop=True), sample_size\n",
    "\n",
    "\n",
    "def calculate_scores(generated_col, reference_col):\n",
    "    cos_scores = []\n",
    "    lev_scores = []\n",
    "    jaro_scores = []\n",
    "\n",
    "    for gen, ref in zip(generated_col, reference_col):\n",
    "        gen, ref = str(gen), str(ref)\n",
    "\n",
    "        # cosine similarity\n",
    "        if nlp:\n",
    "            try:\n",
    "                cos = nlp(gen).similarity(nlp(ref))\n",
    "            except:\n",
    "                cos = 0.0\n",
    "        else:\n",
    "            cos = 0.0\n",
    "        cos_scores.append(cos)\n",
    "\n",
    "        # levenshtein\n",
    "        try:\n",
    "            dist = edit_distance(gen, ref)\n",
    "            mx = max(len(gen), len(ref))\n",
    "            lev = 1 - (dist / mx) if mx > 0 else 1.0\n",
    "        except:\n",
    "            lev = 0.0\n",
    "        lev_scores.append(lev)\n",
    "\n",
    "        # jaro\n",
    "        try:\n",
    "            jaro = jaro_winkler_similarity(gen, ref)\n",
    "        except:\n",
    "            jaro = 0.0\n",
    "        jaro_scores.append(jaro)\n",
    "\n",
    "    return cos_scores, lev_scores, jaro_scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Similarity Metrics\n",
    "We calculate Cosine Similarity (semantic match) and Levenshtein Similarity (exact match) for both models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Cell 4 â€” AI inference function\n",
    "# ============================\n",
    "\n",
    "def run_inference(df, api_key):\n",
    "\n",
    "    # initialize models\n",
    "    few_model = LLM(api_key=api_key, api_model=\"gemini-2.0-flash-exp\", max_examples=None)\n",
    "    base_model = LLM(api_key=api_key, api_model=\"gemini-2.0-flash\", max_examples=0)\n",
    "    base_model.examples = []\n",
    "\n",
    "    few_gen = []\n",
    "    base_gen = []\n",
    "\n",
    "    for cmd in df[\"command\"]:\n",
    "        try:\n",
    "            few_gen.append(few_model.answer(cmd, []))\n",
    "        except:\n",
    "            few_gen.append(\"\")\n",
    "\n",
    "        try:\n",
    "            base_gen.append(base_model.answer(cmd, []))\n",
    "        except:\n",
    "            base_gen.append(\"\")\n",
    "\n",
    "    df[\"few_gen\"] = few_gen\n",
    "    df[\"base_gen\"] = base_gen\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Comparative Results & Visualization\n",
    "Visualizing the improvement gained by using few-shot examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyDGsTwx-RpxCFIDWJKEuD3V4UaaMoaltE0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "       RUN 1 START     \n",
      "==========================\n",
      "Random sample size: 46\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 1 saved in results/run_01\n",
      "\n",
      "==========================\n",
      "       RUN 2 START     \n",
      "==========================\n",
      "Random sample size: 47\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 2 saved in results/run_02\n",
      "\n",
      "==========================\n",
      "       RUN 3 START     \n",
      "==========================\n",
      "Random sample size: 68\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 3 saved in results/run_03\n",
      "\n",
      "==========================\n",
      "       RUN 4 START     \n",
      "==========================\n",
      "Random sample size: 41\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 4 saved in results/run_04\n",
      "\n",
      "==========================\n",
      "       RUN 5 START     \n",
      "==========================\n",
      "Random sample size: 32\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 5 saved in results/run_05\n",
      "\n",
      "==========================\n",
      "       RUN 6 START     \n",
      "==========================\n",
      "Random sample size: 80\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 6 saved in results/run_06\n",
      "\n",
      "==========================\n",
      "       RUN 7 START     \n",
      "==========================\n",
      "Random sample size: 66\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 7 saved in results/run_07\n",
      "\n",
      "==========================\n",
      "       RUN 8 START     \n",
      "==========================\n",
      "Random sample size: 80\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 8 saved in results/run_08\n",
      "\n",
      "==========================\n",
      "       RUN 9 START     \n",
      "==========================\n",
      "Random sample size: 48\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 9 saved in results/run_09\n",
      "\n",
      "==========================\n",
      "       RUN 10 START     \n",
      "==========================\n",
      "Random sample size: 42\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 10 saved in results/run_10\n",
      "\n",
      "==========================\n",
      "       RUN 11 START     \n",
      "==========================\n",
      "Random sample size: 59\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 11 saved in results/run_11\n",
      "\n",
      "==========================\n",
      "       RUN 12 START     \n",
      "==========================\n",
      "Random sample size: 73\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 12 saved in results/run_12\n",
      "\n",
      "==========================\n",
      "       RUN 13 START     \n",
      "==========================\n",
      "Random sample size: 59\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 13 saved in results/run_13\n",
      "\n",
      "==========================\n",
      "       RUN 14 START     \n",
      "==========================\n",
      "Random sample size: 72\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 14 saved in results/run_14\n",
      "\n",
      "==========================\n",
      "       RUN 15 START     \n",
      "==========================\n",
      "Random sample size: 37\n",
      "[*] LLM initialized with 1800 examples.\n",
      "[*] LLM initialized with 0 examples.\n",
      "âœ“ Run 15 saved in results/run_15\n",
      "\n",
      "ðŸŽ‰ All 15 runs completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# Cell 5 â€” Run 15 experiments\n",
    "# ============================\n",
    "\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\") or os.getenv(\"API_KEY\")\n",
    "OUTPUT_DIR = \"results\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "NUM_RUNS = 15\n",
    "\n",
    "for run in range(1, NUM_RUNS + 1):\n",
    "\n",
    "    print(f\"\\n==========================\")\n",
    "    print(f\"       RUN {run} START     \")\n",
    "    print(f\"==========================\")\n",
    "\n",
    "    # --- 1. Random sample ---\n",
    "    df, sample_size = random_sample(df_all)\n",
    "    print(\"Random sample size:\", sample_size)\n",
    "\n",
    "    # --- 2. AI inference ---\n",
    "    df = run_inference(df, api_key)\n",
    "\n",
    "    # --- 3. Metrics ---\n",
    "    df[\"few_cos\"], df[\"few_lev\"], df[\"few_jaro\"] = calculate_scores(df[\"few_gen\"], df[\"response\"])\n",
    "    df[\"base_cos\"], df[\"base_lev\"], df[\"base_jaro\"] = calculate_scores(df[\"base_gen\"], df[\"response\"])\n",
    "\n",
    "    # --- 4. Summary table ---\n",
    "    summary = pd.DataFrame({\n",
    "        \"Model\": [\"Base\", \"Few-Shot\"],\n",
    "        \"Cosine\": [df[\"base_cos\"].mean(), df[\"few_cos\"].mean()],\n",
    "        \"Levenshtein\": [df[\"base_lev\"].mean(), df[\"few_lev\"].mean()],\n",
    "        \"Jaro-Winkler\": [df[\"base_jaro\"].mean(), df[\"few_jaro\"].mean()],\n",
    "        \"Samples\": [sample_size, sample_size]\n",
    "    })\n",
    "\n",
    "    # --- 5. Save files ---\n",
    "    run_dir = f\"{OUTPUT_DIR}/run_{run:02d}\"\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    df.to_csv(f\"{run_dir}/raw_data.csv\", index=False)\n",
    "    summary.to_csv(f\"{run_dir}/summary.csv\", index=False)\n",
    "\n",
    "    # --- 6. Plot ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df[\"base_cos\"], bins=20, color=\"gray\", kde=True, label=\"Base\")\n",
    "    sns.histplot(df[\"few_cos\"], bins=20, color=\"green\", kde=True, label=\"Few-Shot\")\n",
    "    plt.title(f\"Run {run} â€“ Cosine Similarity\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{run_dir}/plot.png\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"âœ“ Run {run} saved in {run_dir}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ All 15 runs completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
